{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np ## Put the imports in here because, for some reason, have to import them each time a new kernel starts, or the plots are plotted over eachother\n",
    "import collections\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.pylab as py\n",
    "import os\n",
    "import csv\n",
    "from collections import Counter\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define helper functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the bash file execution function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def execute(bash_file):\n",
    "    f = open(str(bash_file), 'r')\n",
    "    script = f.read()\n",
    "    subprocess.call(script, shell=True)\n",
    "    print script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def replace_all(text,dic): ## this function takes the string to be searched and a dictionary of replacements\n",
    "    for i, j in dic.iteritems(): #iteritems needed when using dic entries - remember this\n",
    "        text = text.replace(i,j) ## for each dictionary entry, replace the \"key\" with the \"value\" in the text\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Define a cool little helper function for \"natural sorting\". (no idea how it works though!)\n",
    "def natural_key(string_): \n",
    "    return [int(s) if s.isdigit() else s for s in re.split(r'(\\d+)', string_)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the incrementation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np ## Put the imports in here because, for some reason, have to import them each time a new kernel starts, or the plots are plotted over eachother\n",
    "import collections\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.pylab as py\n",
    "import os\n",
    "import csv\n",
    "from collections import Counter\n",
    "import re\n",
    "\n",
    "\n",
    "def IncreMental_U(param, start_value, stop_value, increment, parent_dir_path, file_format, threads):\n",
    "## parent_dir_path - the path to look for raw read .fastq files must have the trailing '/' in it.\n",
    "    \n",
    "    \n",
    "    ##lists and command templates \n",
    "    sample_names = [] \n",
    "    param_values = range(start_value, stop_value, increment)\n",
    "    \n",
    "    ID = 1 ## Assign a different ID to each individual with for a given param value\n",
    "    \n",
    "    for i in os.listdir(parent_dir_path):\n",
    "        if i.endswith(\".fq_1\") or i.endswith(\".fq\") or i.endswith(\"1.fastq\"): \n",
    "            sample_names.append(i)\n",
    "    sample_names = sorted(sample_names) ## Important line - as Incremental_C sorts as well and assigns samples to lists on the basis of their IDs they must be sorted the same way here\n",
    "    \n",
    "    print \"samples present\", sample_names\n",
    "    print (\"Parameter values =\" + str(param_values))\n",
    "    \n",
    "   \n",
    "    for sample in sample_names: ## so for each sample ...\n",
    "\n",
    "    \n",
    "    ## if statement determines the parameter to increment\n",
    "\n",
    "        if param == 'M':\n",
    "            Mcommand_list = []\n",
    "            Mcommand_list_final = []\n",
    "            param_value_list = []\n",
    "            Mcommand = 'mkdir '+ parent_dir_path + str(sample[:-6])+ '/M_tests/M_x/; ustacks -t file_format -M x -m 6 -p threads -d -r -i '+str(ID)+' -f '+ parent_dir_path + 'input_file -o '+ parent_dir_path + str(sample[:-6])+ '/M_tests/M_x/ ;\\n'\n",
    "            for value in param_values:\n",
    "                param_value_list.append(str(value))\n",
    "\n",
    "            ## -N left as default(M+2)\n",
    "            ## -m kept at 6\n",
    "            ## These can be iterated by modifying the Mcommand or mcommand, likewise -d and -r can be removed if needed\n",
    "        \n",
    "            ## for each parameter value, replace the 'x' with the value and add it to the list for the bash script\n",
    "            for value in param_value_list:\n",
    "                Mcommand_list.append(Mcommand.replace(\"x\", value))\n",
    "\n",
    "            ## replacing the rest of the script template with useful values:\n",
    "            ## define a dictionary of replacements - the keys are the strings to be replaced, the values are the replacements\n",
    "            reps = {\"file_format\":str(file_format), \"threads\":str(threads), \"input_file\": str(sample)}\n",
    "        \n",
    "            ## note that the values have to be strings for .replace to be able to use them, so str() must be used here\n",
    "        \n",
    "            ## use the replace all function to replace the template strings with usefer given values or strings \n",
    "            for Mcommand in Mcommand_list:\n",
    "                Mcommand_list_final.append(replace_all(Mcommand, reps))\n",
    "            \n",
    "            f = open(str(parent_dir_path + sample[:-6]+\"_Ustacks_M_commands.sh\"), 'w') ## .. make a bash script file in the current ipython directory...\n",
    "            f.write(\"#!/bin/bash\\n\\nmkdir \"+ parent_dir_path + sample[:-6]+\"\\nmkdir \"+parent_dir_path +sample[:-6]+\"/M_tests/\\n\") ## .. append a few lines for directory management...\n",
    "            \n",
    "            for command in Mcommand_list_final:\n",
    "                f.write(command)\n",
    "            f.close()\n",
    "            \n",
    "            ID += 1 \n",
    "            execute(str(parent_dir_path + sample[:-6]+\"_Ustacks_M_commands.sh\")) ## Finally, excecute the file\n",
    "            \n",
    "            \n",
    "    \n",
    "        elif param == \"m\":\n",
    "            mcommand_list = []\n",
    "            mcommand_list_final = []\n",
    "            param_value_list = []\n",
    "            mcommand = 'mkdir '+ parent_dir_path + str(sample[:-6])+ '/m_tests/m_x/; ustacks -t file_format -M 3 -m x -p threads -d -r -i '+str(ID)+' -f '+ parent_dir_path + 'input_file -o '+ parent_dir_path + str(sample[:-6])+ '/m_tests/m_x/ ;\\n'\n",
    "            for value in param_values:\n",
    "                param_value_list.append(str(value))\n",
    "     \n",
    "            for value in param_value_list:\n",
    "                mcommand_list.append(mcommand.replace(\"x\", value))\n",
    "\n",
    "            ## define a dictionary of replacements - the keys are the strings to be replaced, the values are the replacements\n",
    "            reps = {\"file_format\":str(file_format), \"threads\":str(threads), \"input_file\": str(sample)}\n",
    "            ## note that the values have to be strings for .replace to be able to use them, so str() is used here\n",
    "\n",
    "            for mcommand in mcommand_list:\n",
    "                mcommand_list_final.append(replace_all(mcommand, reps))\n",
    "            \n",
    "            f = open(str(parent_dir_path + sample[:-6]+\"_Ustacks_m_commands.sh\"), 'w') ## .. make a bash script file in the current ipython directory...\n",
    "            f.write(\"#!/bin/bash\\n\\nmkdir \"+parent_dir_path + sample[:-6]+\"\\nmkdir \"+ parent_dir_path + sample[:-6]+\"/m_tests/\\n\") ## .. append a few lines for directory management...\n",
    "            \n",
    "            for command in mcommand_list_final:\n",
    "                f.write(command)\n",
    "            f.close()\n",
    "                \n",
    "\n",
    "            ID += 1 \n",
    "            execute(str(parent_dir_path +sample[:-6]+\"_Ustacks_m_commands.sh\")) ## Finally, excecute the file\n",
    "            \n",
    "            \n",
    "            ### Max-stacks-per-locus ###\n",
    "            \n",
    "        elif param == \"MS\":\n",
    "            mcommand_list = []\n",
    "            mcommand_list_final = []\n",
    "            param_value_list = []\n",
    "            mcommand = 'mkdir '+ parent_dir_path + str(sample[:-6])+ '/MS_tests/MS_z/; ustacks -t file_format -M 3 -m 6 -p threads --max_locus_stacks z -d -r -i '+str(ID)+' -f '+ parent_dir_path + 'input_file -o '+ parent_dir_path + str(sample[:-6])+ '/MS_tests/MS_z/ ;\\n'\n",
    "            for value in param_values:\n",
    "                param_value_list.append(str(value))\n",
    "            \n",
    "            for value in param_value_list:\n",
    "                mcommand_list.append(mcommand.replace(\"z\", value))\n",
    "\n",
    "            ## define a dictionary of replacements - the keys are the strings to be replaced, the values are the replacements\n",
    "            reps = {\"file_format\":str(file_format), \"threads\":str(threads), \"input_file\": str(sample)}\n",
    "            ## note that the values have to be strings for .replace to be able to use them, so str() is used here\n",
    "\n",
    "            for mcommand in mcommand_list:\n",
    "                mcommand_list_final.append(replace_all(mcommand, reps))\n",
    "            \n",
    "            f = open(str(parent_dir_path + sample[:-6]+\"_Ustacks_MS_commands.sh\"), 'w') ## .. make a bash script file in the current ipython directory...\n",
    "            f.write(\"#!/bin/bash\\n\\nmkdir \"+parent_dir_path + sample[:-6]+\"\\nmkdir \"+ parent_dir_path + sample[:-6]+\"/MS_tests/\\n\") ## .. append a few lines for directory management...\n",
    "            \n",
    "            for command in mcommand_list_final:\n",
    "                f.write(command)\n",
    "            f.close()\n",
    "                \n",
    "\n",
    "            ID += 1 \n",
    "            execute(str(parent_dir_path +sample[:-6]+\"_Ustacks_MS_commands.sh\")) ## Finally, excecute the file\n",
    "            \n",
    "    \n",
    "    \n",
    "        \n",
    "    #### This works from any dir, whether you're using M or m #####\n",
    "            \n",
    "\n",
    "        \n",
    "    ## TAG COUNTER ##         \n",
    "    def Tag_counter(directory, parameter):\n",
    "        c = Counter()\n",
    "        sample_names = []\n",
    "        tag_data = []\n",
    "        names = []\n",
    "    \n",
    "\n",
    "    \n",
    "        ## Another cool function to count the length of a file\n",
    "    \n",
    "        def file_len(data):\n",
    "                for i, l in enumerate(data):\n",
    "                    pass\n",
    "                return i + 1\n",
    "    \n",
    "\n",
    "        ## get file names and paths\n",
    "        if parameter == 'm':\n",
    "            for root, dirs, files in os.walk(parent_dir_path):\n",
    "                for fil in files:\n",
    "                    if fil.endswith(\"tags.tsv\") and 'catalog' not in fil and root.split('/')[11].startswith('m'):\n",
    "                        print fil\n",
    "                        data_file = open(str(root+'/'+fil), 'r')\n",
    "                        tag_tally = 0\n",
    "                        for line in data_file.readlines():\n",
    "                            if 'consensus' in line:\n",
    "                                tag_tally +=1\n",
    "                        tag_data.append(str(root.split('/')[-1])+'/'+str(fil)+\"\\t\"+str(tag_tally)) ## works nicely just put this into a list with sample name and its nearly done\n",
    "                        print data_file\n",
    "            tag_data = sorted(tag_data, key = natural_key)\n",
    "            f = open(directory + \"m_tests_Tag_numbers.txt\", 'w')\n",
    "            for i in tag_data:\n",
    "                print i\n",
    "                f.write(i+\"\\n\")\n",
    "            f.close()\n",
    "\n",
    "    \n",
    "            ## get the sample names\n",
    "            for i in tag_data:\n",
    "                names.append(i.split('\\t')[0].split('/')[-1])\n",
    "            names = set(names)\n",
    "            print names    \n",
    "            ##plot the figures\n",
    "            fig = plt.figure()\n",
    "            plt.subplots_adjust(hspace = 0.5) ## adjust subplots\n",
    "            plot_number =1\n",
    "            for i in names:\n",
    "                tag_numbers = []\n",
    "                for item in tag_data:\n",
    "                    if i in item:\n",
    "                        tag_numbers.append(int(item.split('\\t')[1]))\n",
    "                print \"TAG COUNTER\\n\", i, tag_numbers\n",
    "                fig.add_subplot(np.round((len(names)/2)+1),2,plot_number)\n",
    "                plt.scatter(range(start_value, stop_value, increment),tag_numbers) ## Manually input the same parameter range used in incremental IncreMental here for the x axis labels.\n",
    "                plt.plot(range(start_value, stop_value, increment),tag_numbers)\n",
    "                plt.title(i+\" Change in number of tags with m incrementation\", fontsize = 5)\n",
    "                plt.xlabel(\"Ustacks m Value\", fontsize = 10)\n",
    "                plt.ylabel(\"Number of tags\", fontsize = 10)\n",
    "                plt.xticks(fontsize = 7)\n",
    "                plt.yticks(fontsize = 7)\n",
    "        \n",
    "                tag_numbers = []\n",
    "                plot_number+=1\n",
    "            plt.savefig(directory + \"m_tests_Tags_per_sample.pdf\")\n",
    "            plt.close('all')  \n",
    "            \n",
    "        elif parameter == 'M':\n",
    "            for root, dirs, files in os.walk(parent_dir_path):\n",
    "                for fil in files:\n",
    "                    if fil.endswith(\"tags.tsv\") and 'catalog' not in fil and root.split('/')[-1].startswith('M'):\n",
    "                        print fil\n",
    "                        data_file = open(str(root+'/'+fil), 'r')\n",
    "                        tag_tally = 0\n",
    "                        for line in data_file.readlines():\n",
    "                            if 'consensus' in line:\n",
    "                                tag_tally +=1\n",
    "                        tag_data.append(str(root.split('/')[-1])+'/'+str(fil)+\"\\t\"+str(tag_tally)) ## works nicely just put this into a list with sample name and its nearly done\n",
    "                        print data_file\n",
    "            tag_data = sorted(tag_data, key = natural_key)\n",
    "            f = open(directory + \"M_tests_Tag_numbers.txt\", 'w')\n",
    "            for i in tag_data:\n",
    "                print i\n",
    "                f.write(i+\"\\n\")\n",
    "            f.close()\n",
    "\n",
    "    \n",
    "            ## get the sample names\n",
    "            for i in tag_data:\n",
    "                names.append(i.split('\\t')[0].split('/')[-1])\n",
    "            names = set(names)\n",
    "            print names    \n",
    "            ##plot the figures\n",
    "            fig = plt.figure()\n",
    "            plt.subplots_adjust(hspace = 0.5) ## adjust subplots\n",
    "            plot_number =1\n",
    "            for i in names:\n",
    "                tag_numbers = []\n",
    "                for item in tag_data:\n",
    "                    if i in item:\n",
    "                        tag_numbers.append(int(item.split('\\t')[1]))\n",
    "                print \"TAG COUNTER\\n\", i, tag_numbers\n",
    "                fig.add_subplot(np.round((len(names)/2)+1),2,plot_number)\n",
    "                plt.scatter(range(start_value, stop_value, increment),tag_numbers) ## Manually input the same parameter range used in incremental IncreMental here for the x axis labels.\n",
    "                plt.plot(range(start_value, stop_value, increment),tag_numbers)\n",
    "                plt.title(i+\" Change in number of tags with M incrementation\", fontsize = 5)\n",
    "                plt.xlabel(\"Ustacks m Value\", fontsize = 10)\n",
    "                plt.ylabel(\"Number of tags\", fontsize = 10)\n",
    "                plt.xticks(fontsize = 7)\n",
    "                plt.yticks(fontsize = 7)\n",
    "        \n",
    "                tag_numbers = []\n",
    "                plot_number+=1\n",
    "            plt.savefig(directory + \"M_tests_Tags_per_sample.pdf\")\n",
    "            plt.close('all')\n",
    "            \n",
    "        ## Max-stacks-per-locus ###\n",
    "        \n",
    "        elif parameter == \"MS\":\n",
    "            for root, dirs, files in os.walk(parent_dir_path):\n",
    "                for fil in files:\n",
    "                    if fil.endswith(\"tags.tsv\") and 'catalog' not in fil and root.split('/')[-1].startswith('MS'):\n",
    "                        print fil\n",
    "                        data_file = open(str(root+'/'+fil), 'r')\n",
    "                        tag_tally = 0\n",
    "                        for line in data_file.readlines():\n",
    "                            if 'consensus' in line:\n",
    "                                tag_tally +=1\n",
    "                        tag_data.append(str(root.split('/')[-1])+'/'+str(fil)+\"\\t\"+str(tag_tally)) ## works nicely just put this into a list with sample name and its nearly done\n",
    "                        print data_file\n",
    "            tag_data = sorted(tag_data, key = natural_key)\n",
    "            f = open(directory + \"MS_tests_Tag_numbers.txt\", 'w')\n",
    "            for i in tag_data:\n",
    "                print i\n",
    "                f.write(i+\"\\n\")\n",
    "            f.close()\n",
    "            \n",
    "        ## get the sample names\n",
    "            for i in tag_data:\n",
    "                names.append(i.split('\\t')[0].split('/')[-1])\n",
    "            names = set(names)\n",
    "            print names    \n",
    "            \n",
    "        ##plot the figures\n",
    "            \n",
    "            fig = plt.figure()\n",
    "            plt.subplots_adjust(hspace = 0.5) ## adjust subplots\n",
    "            plot_number =1\n",
    "            for i in names:\n",
    "                tag_numbers = []\n",
    "                for item in tag_data:\n",
    "                    if i in item:\n",
    "                        tag_numbers.append(int(item.split('\\t')[1]))\n",
    "                print \"TAG COUNTER\\n\", i, tag_numbers\n",
    "                fig.add_subplot(np.round((len(names)/2)+1),2,plot_number)\n",
    "                plt.scatter(range(start_value, stop_value, increment),tag_numbers) ## Manually input the same parameter range used in incremental IncreMental here for the x axis labels.\n",
    "                plt.plot(range(start_value, stop_value, increment),tag_numbers)\n",
    "                plt.title(i+\" Change in number of tags with Max_locus_stacks incrementation\", fontsize = 5)\n",
    "                plt.xlabel(\"Ustacks M_L_S Value\", fontsize = 10)\n",
    "                plt.ylabel(\"Number of tags\", fontsize = 10)\n",
    "                plt.xticks(fontsize = 7)\n",
    "                plt.yticks(fontsize = 7)\n",
    "        \n",
    "                tag_numbers = []\n",
    "                plot_number+=1\n",
    "            plt.savefig(directory + \"MS_tests_Tags_per_sample.pdf\")\n",
    "            plt.close('all')\n",
    "        \n",
    "    Tag_counter(parent_dir_path, param)\n",
    "    \n",
    "    ## COVERAGE COUNTER ##\n",
    "    \n",
    "    def coverage_counter(file_name):\n",
    "        csvcol3 = []\n",
    "        csvfile = open(file_name, 'rb')\n",
    "        csvread = csv.reader(csvfile, delimiter =\"\\t\") ## read csv in\n",
    "    \n",
    "        for line in csvread:\n",
    "            csvcol3.append(int(line[2])) ## add the 3 column of each line to a list\n",
    "        csvcol3 = [str(i) for i in csvcol3] ## convert this list of integers to strings\n",
    "    \n",
    "        coverage_count = collections.Counter()\n",
    "        for tagID in csvcol3:\n",
    "            coverage_count[tagID] += 1 ## count the number of times each tag ID occurs (i.e. the coverage)\n",
    "    \n",
    "        coverage_values = []\n",
    "        f = open(str(file_name[:-9]+\" Coverage data.txt\"), 'a') ## make a new txt file for coverage data\n",
    "    \n",
    "        for i,j in coverage_count.iteritems():\n",
    "            if len(str(j)) > 0:\n",
    "                coverage_values.append(j) ## append the coverage to a list\n",
    "                f.write(str(j) + '\\n') ## write the coverage data to the txt file\n",
    "    \n",
    "        plt.hist(coverage_values, bins = max(coverage_values),range = [0, 100])\n",
    "        plt.hist(coverage_values, bins = max(coverage_values),range = [0, 100])\n",
    "        plt.title(file_name[2:8]+file_name[27:33])\n",
    "        plt.xlabel(\"Coverage\")\n",
    "        plt.ylabel(\"Frequency\")\n",
    "        plt.text(60, 1200, \"Mean tag coverage =\"+ str(np.round(np.mean(coverage_values),2)))\n",
    "        plt.savefig(file_name.rpartition('/')[0]+\"/Coverage.pdf\")\n",
    "        plt.close()\n",
    "    \n",
    "        f.close()\n",
    "        print coverage_values[:10]\n",
    "        \n",
    "        ## COVERAGE COUNTER LOOPER ## \n",
    "        \n",
    "    def coverage_counter_looper(directory, parameter): ## make sure this is the right parent directory - i.e. contains the sample name folder created by increMental\n",
    "        tsvs = []\n",
    "        subdirs = []\n",
    "        cov_files = []\n",
    "        \n",
    "        ### BIG if statement - if the parameter is M or m\n",
    "    \n",
    "        if parameter == 'M':\n",
    "        \n",
    "        ## Make a list of the files, including their paths from the current directory\n",
    "        \n",
    "            for root, dirs, files in os.walk(str(directory)):\n",
    "                for fil in files:\n",
    "                    if fil.endswith(\".tags.tsv\") and 'catalog' not in fil and 'M_' in root:\n",
    "                        tsvs.append(str(str(root)+'/'+str(fil)))\n",
    "                        subdirs.append(str(str(root)+'/'+str(dirs)))\n",
    "                        print root, fil\n",
    "    \n",
    "            ## Execute coverage counter for all these files\n",
    "    \n",
    "            for tsv in tsvs:\n",
    "                coverage_counter(tsv)           \n",
    "    \n",
    "            ## make the multiplot\n",
    "            ## first get the coverage counter output files\n",
    "    \n",
    "            for root, dirs, files in os.walk(str(directory)):\n",
    "                for fil in files:\n",
    "                    if fil.endswith(\"data.txt\") and 'catalog' not in fil and 'M_' in root:  ## have changed this so hopefully it doesn't pick up increMental_C outputs\n",
    "                        cov_files.append(str(str(root)+'/'+str(fil)))\n",
    "            cov_files = sorted(cov_files, key = natural_key)\n",
    "            plot_number = 1\n",
    "\n",
    "            fig = plt.figure()\n",
    "            plt.subplots_adjust(hspace = 0.8)\n",
    "            data = []\n",
    "            for cov_file in cov_files:    \n",
    "                data_file = open(cov_file, 'r')\n",
    "                for i in data_file.readlines():\n",
    "                    if i > 0:\n",
    "                        data.append(int(i))    \n",
    "    \n",
    "                fig.add_subplot(np.round((len(cov_files)/3)+1),3,plot_number)\n",
    "                plt.hist(data, bins = 100,range = [0, 150])\n",
    "                plt.title(cov_file.split('/')[-1].partition('_')[0]+\" \"+ cov_file.split('/')[-2], fontsize = 5)\n",
    "                py.yticks(fontsize = 5)\n",
    "                py.xticks(fontsize = 5)\n",
    "                plt.xlabel(\"Coverage\", fontsize = 5)\n",
    "                plt.ylabel(\"Frequency\", fontsize = 5)\n",
    "                plt.text(60, 1200, \"Mean tag coverage =\"+ str(np.round(float(np.mean(data)),2)), fontsize = 5)\n",
    "    \n",
    "                plot_number += 1\n",
    "\n",
    "            plt.savefig(directory + 'M_tests_coverage_multiplot.pdf')    \n",
    "            plt.close('all')\n",
    "    \n",
    "    \n",
    "            print('number of coverage plots = '+ str(plot_number -1))\n",
    "    \n",
    "            ### Make the change-in average coverage plot\n",
    "    \n",
    "            sample_coverage = []\n",
    "            sample_names = []\n",
    "            cov_data = []\n",
    "            cov_values = []\n",
    "\n",
    "\n",
    "\n",
    "            ## get file names and paths\n",
    "\n",
    "            for root, dirs, files in os.walk(directory):\n",
    "                for fil in files:\n",
    "                    if fil.endswith(\"data.txt\") and 'M_' in root:\n",
    "                        data_file = open(str(root+'/'+fil), 'r')\n",
    "                        data = [int(i.lstrip('0')) for i in data_file.readlines()]\n",
    "                        sample_coverage.append(fil.partition('_')[0] + \"__\" + root.split('/')[3]+\"\\t\"+ str(np.round(np.mean(data),2)))\n",
    "\n",
    "            ## make a list of uniq sample names\n",
    "\n",
    "            for i in sample_coverage:\n",
    "                sample_names.append(i.split('\\t')[0].partition('_')[0])\n",
    "            sample_names = set(sample_names)\n",
    "            print \"sample names =\" \n",
    "            print sample_names\n",
    "\n",
    "            ## Use this list to separate the data according to the sample it comes from\n",
    "            ## And then plot the graphs in one file and save in parent directory\n",
    "    \n",
    "            fig = plt.figure() ## make fig\n",
    "            plt.subplots_adjust(hspace = 0.5) ## adjust subplots\n",
    "            plot_number =1\n",
    "            for name in sample_names: ## for each sample\n",
    "                for line in sample_coverage:\n",
    "                    if name in line:\n",
    "                        cov_data.append(line)\n",
    "                cov_data = sorted(cov_data, key = natural_key) ## sort \"naturally\"\n",
    "                for i in cov_data:\n",
    "                    cov_values.append(float(i.split()[1]))\n",
    "                print name\n",
    "                print cov_values\n",
    "    \n",
    "            ## And now plot the graphs as subplots in a main fig. Put in parent dir.   \n",
    "    \n",
    "                fig.add_subplot(np.round((len(sample_names)/2)+1),2,plot_number)\n",
    "                plt.scatter(range(start_value, stop_value, increment),cov_values) ## Manually input range from IncreMental here!\n",
    "                plt.plot(range(start_value, stop_value, increment),cov_values)\n",
    "                plt.title(name+\" coverage per tag with M incrementation\", fontsize = 10)\n",
    "                plt.xlabel(\"Ustacks Parameter Value\", fontsize = 10)\n",
    "                plt.ylabel(\"Coverage per tag\", fontsize = 10)\n",
    "                plt.xticks(fontsize = 7)\n",
    "                plt.yticks(fontsize = 7)\n",
    "    \n",
    "                cov_data = []\n",
    "                cov_values = []\n",
    "                plot_number+=1\n",
    "            plt.savefig(directory + \"M_tests_mean_coverage_multiplot.pdf\")\n",
    "            plt.close('all')\n",
    "        \n",
    "        elif parameter == 'm':\n",
    "        \n",
    "        ## Make a list of the files, including their paths from the current directory\n",
    "        \n",
    "            for root, dirs, files in os.walk(str(directory)):\n",
    "                for fil in files:\n",
    "                    if fil.endswith(\".tags.tsv\") and 'catalog' not in fil and 'm_' in root:\n",
    "                        tsvs.append(str(str(root)+'/'+str(fil)))\n",
    "                        print root, fil\n",
    "    \n",
    "            ## Execute coverage counter for all these files\n",
    "    \n",
    "            for tsv in tsvs:\n",
    "                coverage_counter(tsv)           \n",
    "    \n",
    "            ## make the multiplot\n",
    "            ## first get the coverage counter output files\n",
    "    \n",
    "            for root, dirs, files in os.walk(str(directory)):\n",
    "                for fil in files:\n",
    "                    if fil.endswith(\"data.txt\") and 'catalog' not in fil and 'm_' in root:  ## have changed this so hopefully it doesn't pick up increMental_C outputs\n",
    "                        cov_files.append(str(str(root)+'/'+str(fil)))\n",
    "            cov_files = sorted(cov_files, key = natural_key)          \n",
    "            plot_number = 1\n",
    "            \n",
    "            fig = plt.figure()\n",
    "            plt.subplots_adjust(hspace = 0.8)\n",
    "\n",
    "            for cov_file in cov_files:    \n",
    "                print cov_file\n",
    "                data_file = open(cov_file, 'r')\n",
    "                data = [int(i) for i in data_file.readlines()]\n",
    "\n",
    "                fig.add_subplot(np.round((len(cov_files)/3)+1),3,plot_number)\n",
    "                plt.hist(data, bins = 100,range = [0, 150])\n",
    "                plt.title(cov_file.split('/')[-1].partition('_')[0]+\" \"+ cov_file.split('/')[-3], fontsize = 5)\n",
    "                py.yticks(fontsize = 5)\n",
    "                py.xticks(fontsize = 5)\n",
    "                plt.xlabel(\"Coverage\", fontsize = 5)\n",
    "                plt.ylabel(\"Frequency\", fontsize = 5)\n",
    "                plt.text(60, 1200, \"Mean tag coverage =\"+ str(np.round(float(np.mean(data)),2)), fontsize = 5)\n",
    "    \n",
    "                plot_number += 1\n",
    "\n",
    "            plt.savefig(directory + 'm_tests_coverage_multiplot.pdf')    \n",
    "            plt.close('all')\n",
    "    \n",
    "    \n",
    "            print('number of coverage plots = '+ str(plot_number -1))\n",
    "    \n",
    "            ### Make the change-in average coverage plot\n",
    "    \n",
    "            sample_coverage = []\n",
    "            sample_names = []\n",
    "            cov_data = []\n",
    "            cov_values = []\n",
    "\n",
    "\n",
    "            ## get file names and paths\n",
    "\n",
    "            for root, dirs, files in os.walk(directory):\n",
    "                for fil in files:\n",
    "                    if fil.endswith(\"data.txt\") and 'm_' in root:\n",
    "                        data_file = open(str(root+'/'+fil), 'r')\n",
    "                        data = [int(i) for i in data_file.readlines()]\n",
    "                        sample_coverage.append(fil.partition('_')[0] + \"__\" + root.split('/')[3]+\"\\t\"+ str(np.round(np.mean(data),2)))\n",
    "\n",
    "            ## make a list of uniq sample names\n",
    "\n",
    "            for i in sample_coverage:\n",
    "                sample_names.append(i.split('\\t')[0].partition('_')[0])\n",
    "            sample_names = set(sample_names)\n",
    "            print \"sample names =\" \n",
    "            print sample_names\n",
    "\n",
    "            ## Use this list to separate the data according to the sample it comes from\n",
    "            ## And then plot the graphs in one file and save in parent directory\n",
    "    \n",
    "            fig = plt.figure() ## make fig\n",
    "            plt.subplots_adjust(hspace = 0.5) ## adjust subplots\n",
    "            plot_number =1\n",
    "            for name in sample_names: ## for each sample\n",
    "                for line in sample_coverage:\n",
    "                    if name in line:\n",
    "                        cov_data.append(line)\n",
    "                cov_data = sorted(cov_data, key = natural_key) ## sort \"naturally\"\n",
    "                for i in cov_data:\n",
    "                    cov_values.append(float(i.split()[1]))\n",
    "                print name\n",
    "                print cov_values\n",
    "    \n",
    "            ## And now plot the graphs as subplots in a main fig. Put in parent dir.   \n",
    "    \n",
    "                fig.add_subplot(np.round((len(sample_names)/2)+1),2,plot_number)\n",
    "                plt.scatter(range(start_value, stop_value, increment),cov_values) ## remember to change back to start_value, stop_value, increment\n",
    "                plt.plot(range(start_value, stop_value, increment),cov_values)\n",
    "                plt.title(name+\" coverage per tag with m incrementation\", fontsize = 10)\n",
    "                plt.xlabel(\"Ustacks Parameter Value\", fontsize = 10)\n",
    "                plt.ylabel(\"Coverage per tag\", fontsize = 10)\n",
    "                plt.xticks(fontsize = 7)\n",
    "                plt.yticks(fontsize = 7)\n",
    "    \n",
    "                cov_data = []\n",
    "                cov_values = []\n",
    "                plot_number+=1\n",
    "            plt.savefig(directory + \"m_tests_mean_coverage_multiplot.pdf\")\n",
    "            plt.close('all')\n",
    "            \n",
    "        elif parameter == \"MS\":\n",
    "            ## Make a list of the files, including their paths from the current directory\n",
    "        \n",
    "            for root, dirs, files in os.walk(str(directory)):\n",
    "                for fil in files:\n",
    "                    if fil.endswith(\".tags.tsv\") and 'catalog' not in fil and 'MS_' in root:\n",
    "                        tsvs.append(str(str(root)+'/'+str(fil)))\n",
    "                        print root, fil\n",
    "    \n",
    "            ## Execute coverage counter for all these files\n",
    "    \n",
    "            for tsv in tsvs:\n",
    "                coverage_counter(tsv)           \n",
    "    \n",
    "            ## make the multiplot\n",
    "            ## first get the coverage counter output files\n",
    "    \n",
    "            for root, dirs, files in os.walk(str(directory)):\n",
    "                for fil in files:\n",
    "                    if fil.endswith(\"data.txt\") and 'catalog' not in fil and 'MS_' in root:  ## have changed this so hopefully it doesn't pick up increMental_C outputs\n",
    "                        cov_files.append(str(str(root)+'/'+str(fil)))\n",
    "            cov_files = sorted(cov_files, key = natural_key)          \n",
    "            plot_number = 1\n",
    "            \n",
    "            fig = plt.figure()\n",
    "            plt.subplots_adjust(hspace = 0.8)\n",
    "\n",
    "            for cov_file in cov_files:    \n",
    "                print cov_file\n",
    "                data_file = open(cov_file, 'r')\n",
    "                data = [int(i) for i in data_file.readlines()]\n",
    "\n",
    "                fig.add_subplot(np.round((len(cov_files)/3)+1),3,plot_number)\n",
    "                plt.hist(data, bins = 100,range = [0, 150])\n",
    "                plt.title(cov_file.split('/')[-1].partition('_')[0]+\" \"+ cov_file.split('/')[-3], fontsize = 5)\n",
    "                py.yticks(fontsize = 5)\n",
    "                py.xticks(fontsize = 5)\n",
    "                plt.xlabel(\"Coverage\", fontsize = 5)\n",
    "                plt.ylabel(\"Frequency\", fontsize = 5)\n",
    "                plt.text(60, 1200, \"Mean tag coverage =\"+ str(np.round(float(np.mean(data)),2)), fontsize = 5)\n",
    "    \n",
    "                plot_number += 1\n",
    "\n",
    "            plt.savefig(directory + 'MS_tests_coverage_multiplot.pdf')    \n",
    "            plt.close('all')\n",
    "    \n",
    "    \n",
    "            print('number of coverage plots = '+ str(plot_number -1))\n",
    "        \n",
    "        ### Make the change-in average coverage plot\n",
    "    \n",
    "            sample_coverage = []\n",
    "            sample_names = []\n",
    "            cov_data = []\n",
    "            cov_values = []\n",
    "\n",
    "\n",
    "            ## get file names and paths\n",
    "\n",
    "            for root, dirs, files in os.walk(directory):\n",
    "                for fil in files:\n",
    "                    if fil.endswith(\"data.txt\") and 'MS_' in root:\n",
    "                        data_file = open(str(root+'/'+fil), 'r')\n",
    "                        data = [int(i) for i in data_file.readlines()]\n",
    "                        sample_coverage.append(fil.partition('_')[0] + \"__\" + root.split('/')[3]+\"\\t\"+ str(np.round(np.mean(data),2)))\n",
    "\n",
    "            ## make a list of uniq sample names\n",
    "\n",
    "            for i in sample_coverage:\n",
    "                sample_names.append(i.split('\\t')[0].partition('_')[0])\n",
    "            sample_names = set(sample_names)\n",
    "            print \"sample names =\" \n",
    "            print sample_names\n",
    "\n",
    "            ## Use this list to separate the data according to the sample it comes from\n",
    "            ## And then plot the graphs in one file and save in parent directory\n",
    "    \n",
    "            fig = plt.figure() ## make fig\n",
    "            plt.subplots_adjust(hspace = 0.5) ## adjust subplots\n",
    "            plot_number =1\n",
    "            for name in sample_names: ## for each sample\n",
    "                for line in sample_coverage:\n",
    "                    if name in line:\n",
    "                        cov_data.append(line)\n",
    "                cov_data = sorted(cov_data, key = natural_key) ## sort \"naturally\"\n",
    "                for i in cov_data:\n",
    "                    cov_values.append(float(i.split()[1]))\n",
    "                print name\n",
    "                print cov_values\n",
    "    \n",
    "            ## And now plot the graphs as subplots in a main fig. Put in parent dir.   \n",
    "    \n",
    "                fig.add_subplot(np.round((len(sample_names)/2)+1),2,plot_number)\n",
    "                plt.scatter(range(start_value, stop_value, increment),cov_values) ## remember to change back to start_value, stop_value, increment\n",
    "                plt.plot(range(start_value, stop_value, increment),cov_values)\n",
    "                plt.title(name+\" coverage per tag with Max_Locus_stacks incrementation\", fontsize = 10)\n",
    "                plt.xlabel(\"Ustacks M_L_S Parameter Value\", fontsize = 10)\n",
    "                plt.ylabel(\"Coverage per tag\", fontsize = 10)\n",
    "                plt.xticks(fontsize = 7)\n",
    "                plt.yticks(fontsize = 7)\n",
    "    \n",
    "                cov_data = []\n",
    "                cov_values = []\n",
    "                plot_number+=1\n",
    "            plt.savefig(directory + \"MS_tests_mean_coverage_multiplot.pdf\")\n",
    "            plt.close('all')\n",
    "   \n",
    "    coverage_counter_looper(parent_dir_path, param)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To do:\n",
    "    - Make the if statements more efficient\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples present ['BF04_1.fil.fq', 'EP01_1.fil.fq', 'GBP7_RD-P1-127_1.fil.fq']\n",
      "Parameter values =[1, 2, 3, 4, 5]\n",
      "#!/bin/bash\n",
      "\n",
      "mkdir /media/dan/34D5D1CE642D7E36/2013076_Hanfling_Bernd/Stacks/Stacks_analyses_V3/Incremental_tests/Batch_2/cru_gold_putHyb/BF04_1.\n",
      "mkdir /media/dan/34D5D1CE642D7E36/2013076_Hanfling_Bernd/Stacks/Stacks_analyses_V3/Incremental_tests/Batch_2/cru_gold_putHyb/BF04_1./MS_tests/\n",
      "mkdir /media/dan/34D5D1CE642D7E36/2013076_Hanfling_Bernd/Stacks/Stacks_analyses_V3/Incremental_tests/Batch_2/cru_gold_putHyb/BF04_1./MS_tests/MS_1/; ustacks -t fastq -M 3 -m 6 -p 8 --max_locus_stacks 1 -d -r -i 1 -f /media/dan/34D5D1CE642D7E36/2013076_Hanfling_Bernd/Stacks/Stacks_analyses_V3/Incremental_tests/Batch_2/cru_gold_putHyb/BF04_1.fil.fq -o /media/dan/34D5D1CE642D7E36/2013076_Hanfling_Bernd/Stacks/Stacks_analyses_V3/Incremental_tests/Batch_2/cru_gold_putHyb/BF04_1./MS_tests/MS_1/ ;\n",
      "mkdir /media/dan/34D5D1CE642D7E36/2013076_Hanfling_Bernd/Stacks/Stacks_analyses_V3/Incremental_tests/Batch_2/cru_gold_putHyb/BF04_1./MS_tests/MS_2/; ustacks -t fastq -M 3 -m 6 -p 8 --max_locus_stacks 2 -d -r -i 1 -f /media/dan/34D5D1CE642D7E36/2013076_Hanfling_Bernd/Stacks/Stacks_analyses_V3/Incremental_tests/Batch_2/cru_gold_putHyb/BF04_1.fil.fq -o /media/dan/34D5D1CE642D7E36/2013076_Hanfling_Bernd/Stacks/Stacks_analyses_V3/Incremental_tests/Batch_2/cru_gold_putHyb/BF04_1./MS_tests/MS_2/ ;\n",
      "mkdir /media/dan/34D5D1CE642D7E36/2013076_Hanfling_Bernd/Stacks/Stacks_analyses_V3/Incremental_tests/Batch_2/cru_gold_putHyb/BF04_1./MS_tests/MS_3/; ustacks -t fastq -M 3 -m 6 -p 8 --max_locus_stacks 3 -d -r -i 1 -f /media/dan/34D5D1CE642D7E36/2013076_Hanfling_Bernd/Stacks/Stacks_analyses_V3/Incremental_tests/Batch_2/cru_gold_putHyb/BF04_1.fil.fq -o /media/dan/34D5D1CE642D7E36/2013076_Hanfling_Bernd/Stacks/Stacks_analyses_V3/Incremental_tests/Batch_2/cru_gold_putHyb/BF04_1./MS_tests/MS_3/ ;\n",
      "mkdir /media/dan/34D5D1CE642D7E36/2013076_Hanfling_Bernd/Stacks/Stacks_analyses_V3/Incremental_tests/Batch_2/cru_gold_putHyb/BF04_1./MS_tests/MS_4/; ustacks -t fastq -M 3 -m 6 -p 8 --max_locus_stacks 4 -d -r -i 1 -f /media/dan/34D5D1CE642D7E36/2013076_Hanfling_Bernd/Stacks/Stacks_analyses_V3/Incremental_tests/Batch_2/cru_gold_putHyb/BF04_1.fil.fq -o /media/dan/34D5D1CE642D7E36/2013076_Hanfling_Bernd/Stacks/Stacks_analyses_V3/Incremental_tests/Batch_2/cru_gold_putHyb/BF04_1./MS_tests/MS_4/ ;\n",
      "mkdir /media/dan/34D5D1CE642D7E36/2013076_Hanfling_Bernd/Stacks/Stacks_analyses_V3/Incremental_tests/Batch_2/cru_gold_putHyb/BF04_1./MS_tests/MS_5/; ustacks -t fastq -M 3 -m 6 -p 8 --max_locus_stacks 5 -d -r -i 1 -f /media/dan/34D5D1CE642D7E36/2013076_Hanfling_Bernd/Stacks/Stacks_analyses_V3/Incremental_tests/Batch_2/cru_gold_putHyb/BF04_1.fil.fq -o /media/dan/34D5D1CE642D7E36/2013076_Hanfling_Bernd/Stacks/Stacks_analyses_V3/Incremental_tests/Batch_2/cru_gold_putHyb/BF04_1./MS_tests/MS_5/ ;\n",
      "\n",
      "#!/bin/bash\n",
      "\n",
      "mkdir /media/dan/34D5D1CE642D7E36/2013076_Hanfling_Bernd/Stacks/Stacks_analyses_V3/Incremental_tests/Batch_2/cru_gold_putHyb/EP01_1.\n",
      "mkdir /media/dan/34D5D1CE642D7E36/2013076_Hanfling_Bernd/Stacks/Stacks_analyses_V3/Incremental_tests/Batch_2/cru_gold_putHyb/EP01_1./MS_tests/\n",
      "mkdir /media/dan/34D5D1CE642D7E36/2013076_Hanfling_Bernd/Stacks/Stacks_analyses_V3/Incremental_tests/Batch_2/cru_gold_putHyb/EP01_1./MS_tests/MS_1/; ustacks -t fastq -M 3 -m 6 -p 8 --max_locus_stacks 1 -d -r -i 2 -f /media/dan/34D5D1CE642D7E36/2013076_Hanfling_Bernd/Stacks/Stacks_analyses_V3/Incremental_tests/Batch_2/cru_gold_putHyb/EP01_1.fil.fq -o /media/dan/34D5D1CE642D7E36/2013076_Hanfling_Bernd/Stacks/Stacks_analyses_V3/Incremental_tests/Batch_2/cru_gold_putHyb/EP01_1./MS_tests/MS_1/ ;\n",
      "mkdir /media/dan/34D5D1CE642D7E36/2013076_Hanfling_Bernd/Stacks/Stacks_analyses_V3/Incremental_tests/Batch_2/cru_gold_putHyb/EP01_1./MS_tests/MS_2/; ustacks -t fastq -M 3 -m 6 -p 8 --max_locus_stacks 2 -d -r -i 2 -f /media/dan/34D5D1CE642D7E36/2013076_Hanfling_Bernd/Stacks/Stacks_analyses_V3/Incremental_tests/Batch_2/cru_gold_putHyb/EP01_1.fil.fq -o /media/dan/34D5D1CE642D7E36/2013076_Hanfling_Bernd/Stacks/Stacks_analyses_V3/Incremental_tests/Batch_2/cru_gold_putHyb/EP01_1./MS_tests/MS_2/ ;\n",
      "mkdir /media/dan/34D5D1CE642D7E36/2013076_Hanfling_Bernd/Stacks/Stacks_analyses_V3/Incremental_tests/Batch_2/cru_gold_putHyb/EP01_1./MS_tests/MS_3/; ustacks -t fastq -M 3 -m 6 -p 8 --max_locus_stacks 3 -d -r -i 2 -f /media/dan/34D5D1CE642D7E36/2013076_Hanfling_Bernd/Stacks/Stacks_analyses_V3/Incremental_tests/Batch_2/cru_gold_putHyb/EP01_1.fil.fq -o /media/dan/34D5D1CE642D7E36/2013076_Hanfling_Bernd/Stacks/Stacks_analyses_V3/Incremental_tests/Batch_2/cru_gold_putHyb/EP01_1./MS_tests/MS_3/ ;\n",
      "mkdir /media/dan/34D5D1CE642D7E36/2013076_Hanfling_Bernd/Stacks/Stacks_analyses_V3/Incremental_tests/Batch_2/cru_gold_putHyb/EP01_1./MS_tests/MS_4/; ustacks -t fastq -M 3 -m 6 -p 8 --max_locus_stacks 4 -d -r -i 2 -f /media/dan/34D5D1CE642D7E36/2013076_Hanfling_Bernd/Stacks/Stacks_analyses_V3/Incremental_tests/Batch_2/cru_gold_putHyb/EP01_1.fil.fq -o /media/dan/34D5D1CE642D7E36/2013076_Hanfling_Bernd/Stacks/Stacks_analyses_V3/Incremental_tests/Batch_2/cru_gold_putHyb/EP01_1./MS_tests/MS_4/ ;\n",
      "mkdir /media/dan/34D5D1CE642D7E36/2013076_Hanfling_Bernd/Stacks/Stacks_analyses_V3/Incremental_tests/Batch_2/cru_gold_putHyb/EP01_1./MS_tests/MS_5/; ustacks -t fastq -M 3 -m 6 -p 8 --max_locus_stacks 5 -d -r -i 2 -f /media/dan/34D5D1CE642D7E36/2013076_Hanfling_Bernd/Stacks/Stacks_analyses_V3/Incremental_tests/Batch_2/cru_gold_putHyb/EP01_1.fil.fq -o /media/dan/34D5D1CE642D7E36/2013076_Hanfling_Bernd/Stacks/Stacks_analyses_V3/Incremental_tests/Batch_2/cru_gold_putHyb/EP01_1./MS_tests/MS_5/ ;\n",
      "\n",
      "#!/bin/bash\n",
      "\n",
      "mkdir /media/dan/34D5D1CE642D7E36/2013076_Hanfling_Bernd/Stacks/Stacks_analyses_V3/Incremental_tests/Batch_2/cru_gold_putHyb/GBP7_RD-P1-127_1.\n",
      "mkdir /media/dan/34D5D1CE642D7E36/2013076_Hanfling_Bernd/Stacks/Stacks_analyses_V3/Incremental_tests/Batch_2/cru_gold_putHyb/GBP7_RD-P1-127_1./MS_tests/\n",
      "mkdir /media/dan/34D5D1CE642D7E36/2013076_Hanfling_Bernd/Stacks/Stacks_analyses_V3/Incremental_tests/Batch_2/cru_gold_putHyb/GBP7_RD-P1-127_1./MS_tests/MS_1/; ustacks -t fastq -M 3 -m 6 -p 8 --max_locus_stacks 1 -d -r -i 3 -f /media/dan/34D5D1CE642D7E36/2013076_Hanfling_Bernd/Stacks/Stacks_analyses_V3/Incremental_tests/Batch_2/cru_gold_putHyb/GBP7_RD-P1-127_1.fil.fq -o /media/dan/34D5D1CE642D7E36/2013076_Hanfling_Bernd/Stacks/Stacks_analyses_V3/Incremental_tests/Batch_2/cru_gold_putHyb/GBP7_RD-P1-127_1./MS_tests/MS_1/ ;\n",
      "mkdir /media/dan/34D5D1CE642D7E36/2013076_Hanfling_Bernd/Stacks/Stacks_analyses_V3/Incremental_tests/Batch_2/cru_gold_putHyb/GBP7_RD-P1-127_1./MS_tests/MS_2/; ustacks -t fastq -M 3 -m 6 -p 8 --max_locus_stacks 2 -d -r -i 3 -f /media/dan/34D5D1CE642D7E36/2013076_Hanfling_Bernd/Stacks/Stacks_analyses_V3/Incremental_tests/Batch_2/cru_gold_putHyb/GBP7_RD-P1-127_1.fil.fq -o /media/dan/34D5D1CE642D7E36/2013076_Hanfling_Bernd/Stacks/Stacks_analyses_V3/Incremental_tests/Batch_2/cru_gold_putHyb/GBP7_RD-P1-127_1./MS_tests/MS_2/ ;\n",
      "mkdir /media/dan/34D5D1CE642D7E36/2013076_Hanfling_Bernd/Stacks/Stacks_analyses_V3/Incremental_tests/Batch_2/cru_gold_putHyb/GBP7_RD-P1-127_1./MS_tests/MS_3/; ustacks -t fastq -M 3 -m 6 -p 8 --max_locus_stacks 3 -d -r -i 3 -f /media/dan/34D5D1CE642D7E36/2013076_Hanfling_Bernd/Stacks/Stacks_analyses_V3/Incremental_tests/Batch_2/cru_gold_putHyb/GBP7_RD-P1-127_1.fil.fq -o /media/dan/34D5D1CE642D7E36/2013076_Hanfling_Bernd/Stacks/Stacks_analyses_V3/Incremental_tests/Batch_2/cru_gold_putHyb/GBP7_RD-P1-127_1./MS_tests/MS_3/ ;\n",
      "mkdir /media/dan/34D5D1CE642D7E36/2013076_Hanfling_Bernd/Stacks/Stacks_analyses_V3/Incremental_tests/Batch_2/cru_gold_putHyb/GBP7_RD-P1-127_1./MS_tests/MS_4/; ustacks -t fastq -M 3 -m 6 -p 8 --max_locus_stacks 4 -d -r -i 3 -f /media/dan/34D5D1CE642D7E36/2013076_Hanfling_Bernd/Stacks/Stacks_analyses_V3/Incremental_tests/Batch_2/cru_gold_putHyb/GBP7_RD-P1-127_1.fil.fq -o /media/dan/34D5D1CE642D7E36/2013076_Hanfling_Bernd/Stacks/Stacks_analyses_V3/Incremental_tests/Batch_2/cru_gold_putHyb/GBP7_RD-P1-127_1./MS_tests/MS_4/ ;\n",
      "mkdir /media/dan/34D5D1CE642D7E36/2013076_Hanfling_Bernd/Stacks/Stacks_analyses_V3/Incremental_tests/Batch_2/cru_gold_putHyb/GBP7_RD-P1-127_1./MS_tests/MS_5/; ustacks -t fastq -M 3 -m 6 -p 8 --max_locus_stacks 5 -d -r -i 3 -f /media/dan/34D5D1CE642D7E36/2013076_Hanfling_Bernd/Stacks/Stacks_analyses_V3/Incremental_tests/Batch_2/cru_gold_putHyb/GBP7_RD-P1-127_1.fil.fq -o /media/dan/34D5D1CE642D7E36/2013076_Hanfling_Bernd/Stacks/Stacks_analyses_V3/Incremental_tests/Batch_2/cru_gold_putHyb/GBP7_RD-P1-127_1./MS_tests/MS_5/ ;\n",
      "\n",
      "BF04_1.fil.tags.tsv\n",
      "<open file '/media/dan/34D5D1CE642D7E36/2013076_Hanfling_Bernd/Stacks/Stacks_analyses_V3/Incremental_tests/Batch_2/cru_gold_putHyb/BF04_1./MS_tests/MS_1/BF04_1.fil.tags.tsv', mode 'r' at 0x7f94409b6db0>\n",
      "BF04_1.fil.tags.tsv\n",
      "<open file '/media/dan/34D5D1CE642D7E36/2013076_Hanfling_Bernd/Stacks/Stacks_analyses_V3/Incremental_tests/Batch_2/cru_gold_putHyb/BF04_1./MS_tests/MS_2/BF04_1.fil.tags.tsv', mode 'r' at 0x7f94409b65d0>\n",
      "BF04_1.fil.tags.tsv\n",
      "<open file '/media/dan/34D5D1CE642D7E36/2013076_Hanfling_Bernd/Stacks/Stacks_analyses_V3/Incremental_tests/Batch_2/cru_gold_putHyb/BF04_1./MS_tests/MS_3/BF04_1.fil.tags.tsv', mode 'r' at 0x7f94409b6db0>\n",
      "BF04_1.fil.tags.tsv\n",
      "<open file '/media/dan/34D5D1CE642D7E36/2013076_Hanfling_Bernd/Stacks/Stacks_analyses_V3/Incremental_tests/Batch_2/cru_gold_putHyb/BF04_1./MS_tests/MS_4/BF04_1.fil.tags.tsv', mode 'r' at 0x7f94409b65d0>\n",
      "BF04_1.fil.tags.tsv\n",
      "<open file '/media/dan/34D5D1CE642D7E36/2013076_Hanfling_Bernd/Stacks/Stacks_analyses_V3/Incremental_tests/Batch_2/cru_gold_putHyb/BF04_1./MS_tests/MS_5/BF04_1.fil.tags.tsv', mode 'r' at 0x7f94409b6db0>\n",
      "EP01_1.fil.tags.tsv\n",
      "<open file '/media/dan/34D5D1CE642D7E36/2013076_Hanfling_Bernd/Stacks/Stacks_analyses_V3/Incremental_tests/Batch_2/cru_gold_putHyb/EP01_1./MS_tests/MS_1/EP01_1.fil.tags.tsv', mode 'r' at 0x7f94409b65d0>\n",
      "EP01_1.fil.tags.tsv\n",
      "<open file '/media/dan/34D5D1CE642D7E36/2013076_Hanfling_Bernd/Stacks/Stacks_analyses_V3/Incremental_tests/Batch_2/cru_gold_putHyb/EP01_1./MS_tests/MS_2/EP01_1.fil.tags.tsv', mode 'r' at 0x7f94409b6db0>\n",
      "EP01_1.fil.tags.tsv\n",
      "<open file '/media/dan/34D5D1CE642D7E36/2013076_Hanfling_Bernd/Stacks/Stacks_analyses_V3/Incremental_tests/Batch_2/cru_gold_putHyb/EP01_1./MS_tests/MS_3/EP01_1.fil.tags.tsv', mode 'r' at 0x7f94409b65d0>\n",
      "EP01_1.fil.tags.tsv\n",
      "<open file '/media/dan/34D5D1CE642D7E36/2013076_Hanfling_Bernd/Stacks/Stacks_analyses_V3/Incremental_tests/Batch_2/cru_gold_putHyb/EP01_1./MS_tests/MS_4/EP01_1.fil.tags.tsv', mode 'r' at 0x7f94409b6db0>\n",
      "EP01_1.fil.tags.tsv\n",
      "<open file '/media/dan/34D5D1CE642D7E36/2013076_Hanfling_Bernd/Stacks/Stacks_analyses_V3/Incremental_tests/Batch_2/cru_gold_putHyb/EP01_1./MS_tests/MS_5/EP01_1.fil.tags.tsv', mode 'r' at 0x7f94409b65d0>\n",
      "GBP7_RD-P1-127_1.fil.tags.tsv\n",
      "<open file '/media/dan/34D5D1CE642D7E36/2013076_Hanfling_Bernd/Stacks/Stacks_analyses_V3/Incremental_tests/Batch_2/cru_gold_putHyb/GBP7_RD-P1-127_1./MS_tests/MS_1/GBP7_RD-P1-127_1.fil.tags.tsv', mode 'r' at 0x7f94409b6db0>\n",
      "GBP7_RD-P1-127_1.fil.tags.tsv\n",
      "<open file '/media/dan/34D5D1CE642D7E36/2013076_Hanfling_Bernd/Stacks/Stacks_analyses_V3/Incremental_tests/Batch_2/cru_gold_putHyb/GBP7_RD-P1-127_1./MS_tests/MS_2/GBP7_RD-P1-127_1.fil.tags.tsv', mode 'r' at 0x7f94409b65d0>\n",
      "GBP7_RD-P1-127_1.fil.tags.tsv\n",
      "<open file '/media/dan/34D5D1CE642D7E36/2013076_Hanfling_Bernd/Stacks/Stacks_analyses_V3/Incremental_tests/Batch_2/cru_gold_putHyb/GBP7_RD-P1-127_1./MS_tests/MS_3/GBP7_RD-P1-127_1.fil.tags.tsv', mode 'r' at 0x7f94409b6db0>\n",
      "GBP7_RD-P1-127_1.fil.tags.tsv\n",
      "<open file '/media/dan/34D5D1CE642D7E36/2013076_Hanfling_Bernd/Stacks/Stacks_analyses_V3/Incremental_tests/Batch_2/cru_gold_putHyb/GBP7_RD-P1-127_1./MS_tests/MS_4/GBP7_RD-P1-127_1.fil.tags.tsv', mode 'r' at 0x7f94409b65d0>\n",
      "GBP7_RD-P1-127_1.fil.tags.tsv\n",
      "<open file '/media/dan/34D5D1CE642D7E36/2013076_Hanfling_Bernd/Stacks/Stacks_analyses_V3/Incremental_tests/Batch_2/cru_gold_putHyb/GBP7_RD-P1-127_1./MS_tests/MS_5/GBP7_RD-P1-127_1.fil.tags.tsv', mode 'r' at 0x7f94409b6db0>\n",
      "MS_1/BF04_1.fil.tags.tsv\t47133\n",
      "MS_1/EP01_1.fil.tags.tsv\t87658\n",
      "MS_1/GBP7_RD-P1-127_1.fil.tags.tsv\t49510\n",
      "MS_2/BF04_1.fil.tags.tsv\t47133\n",
      "MS_2/EP01_1.fil.tags.tsv\t87658\n",
      "MS_2/GBP7_RD-P1-127_1.fil.tags.tsv\t49510\n",
      "MS_3/BF04_1.fil.tags.tsv\t47133\n",
      "MS_3/EP01_1.fil.tags.tsv\t87658\n",
      "MS_3/GBP7_RD-P1-127_1.fil.tags.tsv\t49510\n",
      "MS_4/BF04_1.fil.tags.tsv\t47133\n",
      "MS_4/EP01_1.fil.tags.tsv\t87658\n",
      "MS_4/GBP7_RD-P1-127_1.fil.tags.tsv\t49510\n",
      "MS_5/BF04_1.fil.tags.tsv\t47133\n",
      "MS_5/EP01_1.fil.tags.tsv\t87658\n",
      "MS_5/GBP7_RD-P1-127_1.fil.tags.tsv\t49510\n",
      "set(['GBP7_RD-P1-127_1.fil.tags.tsv', 'EP01_1.fil.tags.tsv', 'BF04_1.fil.tags.tsv'])\n",
      "TAG COUNTER\n",
      "GBP7_RD-P1-127_1.fil.tags.tsv [49510, 49510, 49510, 49510, 49510]\n",
      "TAG COUNTER\n",
      "EP01_1.fil.tags.tsv [87658, 87658, 87658, 87658, 87658]\n",
      "TAG COUNTER\n",
      "BF04_1.fil.tags.tsv [47133, 47133, 47133, 47133, 47133]\n",
      "/media/dan/34D5D1CE642D7E36/2013076_Hanfling_Bernd/Stacks/Stacks_analyses_V3/Incremental_tests/Batch_2/cru_gold_putHyb/BF04_1./MS_tests/MS_1 BF04_1.fil.tags.tsv\n",
      "/media/dan/34D5D1CE642D7E36/2013076_Hanfling_Bernd/Stacks/Stacks_analyses_V3/Incremental_tests/Batch_2/cru_gold_putHyb/BF04_1./MS_tests/MS_2 BF04_1.fil.tags.tsv\n",
      "/media/dan/34D5D1CE642D7E36/2013076_Hanfling_Bernd/Stacks/Stacks_analyses_V3/Incremental_tests/Batch_2/cru_gold_putHyb/BF04_1./MS_tests/MS_3 BF04_1.fil.tags.tsv\n",
      "/media/dan/34D5D1CE642D7E36/2013076_Hanfling_Bernd/Stacks/Stacks_analyses_V3/Incremental_tests/Batch_2/cru_gold_putHyb/BF04_1./MS_tests/MS_4 BF04_1.fil.tags.tsv\n",
      "/media/dan/34D5D1CE642D7E36/2013076_Hanfling_Bernd/Stacks/Stacks_analyses_V3/Incremental_tests/Batch_2/cru_gold_putHyb/BF04_1./MS_tests/MS_5 BF04_1.fil.tags.tsv\n",
      "/media/dan/34D5D1CE642D7E36/2013076_Hanfling_Bernd/Stacks/Stacks_analyses_V3/Incremental_tests/Batch_2/cru_gold_putHyb/EP01_1./MS_tests/MS_1 EP01_1.fil.tags.tsv\n",
      "/media/dan/34D5D1CE642D7E36/2013076_Hanfling_Bernd/Stacks/Stacks_analyses_V3/Incremental_tests/Batch_2/cru_gold_putHyb/EP01_1./MS_tests/MS_2 EP01_1.fil.tags.tsv\n",
      "/media/dan/34D5D1CE642D7E36/2013076_Hanfling_Bernd/Stacks/Stacks_analyses_V3/Incremental_tests/Batch_2/cru_gold_putHyb/EP01_1./MS_tests/MS_3 EP01_1.fil.tags.tsv\n",
      "/media/dan/34D5D1CE642D7E36/2013076_Hanfling_Bernd/Stacks/Stacks_analyses_V3/Incremental_tests/Batch_2/cru_gold_putHyb/EP01_1./MS_tests/MS_4 EP01_1.fil.tags.tsv\n",
      "/media/dan/34D5D1CE642D7E36/2013076_Hanfling_Bernd/Stacks/Stacks_analyses_V3/Incremental_tests/Batch_2/cru_gold_putHyb/EP01_1./MS_tests/MS_5 EP01_1.fil.tags.tsv\n",
      "/media/dan/34D5D1CE642D7E36/2013076_Hanfling_Bernd/Stacks/Stacks_analyses_V3/Incremental_tests/Batch_2/cru_gold_putHyb/GBP7_RD-P1-127_1./MS_tests/MS_1 GBP7_RD-P1-127_1.fil.tags.tsv\n",
      "/media/dan/34D5D1CE642D7E36/2013076_Hanfling_Bernd/Stacks/Stacks_analyses_V3/Incremental_tests/Batch_2/cru_gold_putHyb/GBP7_RD-P1-127_1./MS_tests/MS_2 GBP7_RD-P1-127_1.fil.tags.tsv\n",
      "/media/dan/34D5D1CE642D7E36/2013076_Hanfling_Bernd/Stacks/Stacks_analyses_V3/Incremental_tests/Batch_2/cru_gold_putHyb/GBP7_RD-P1-127_1./MS_tests/MS_3 GBP7_RD-P1-127_1.fil.tags.tsv\n",
      "/media/dan/34D5D1CE642D7E36/2013076_Hanfling_Bernd/Stacks/Stacks_analyses_V3/Incremental_tests/Batch_2/cru_gold_putHyb/GBP7_RD-P1-127_1./MS_tests/MS_4 GBP7_RD-P1-127_1.fil.tags.tsv\n",
      "/media/dan/34D5D1CE642D7E36/2013076_Hanfling_Bernd/Stacks/Stacks_analyses_V3/Incremental_tests/Batch_2/cru_gold_putHyb/GBP7_RD-P1-127_1./MS_tests/MS_5 GBP7_RD-P1-127_1.fil.tags.tsv\n",
      "[23, 22, 15, 18, 24, 22, 29, 20, 17, 23]\n",
      "[19, 16, 24, 9, 9, 10, 16, 11, 8, 34]\n",
      "[18, 15, 19, 24, 26, 24, 13, 41, 27, 37]\n",
      "[13, 15, 19, 24, 26, 24, 13, 41, 27, 37]\n",
      "[27, 22, 27, 25, 28, 14, 14, 30, 23, 13]\n",
      "[17, 17, 26, 30, 15, 15, 21, 75, 31, 20]\n",
      "[17, 9, 26, 31, 15, 15, 21, 82, 27, 20]\n",
      "[27, 19, 11, 12, 13, 20, 15, 20, 21, 25]\n",
      "[27, 24, 26, 31, 15, 15, 21, 82, 27, 20]\n",
      "[16, 24, 26, 31, 15, 15, 21, 82, 27, 20]\n",
      "[19, 25, 12, 10, 23, 18, 25, 26, 10, 36]\n",
      "[10, 36, 18, 15, 28, 20, 33, 34, 36, 34]\n",
      "[19, 29, 39, 42, 36, 12, 29, 19, 12, 35]\n",
      "[17, 51, 23, 30, 22, 22, 13, 31, 56, 12]\n",
      "[26, 14, 23, 14, 42, 36, 24, 12, 24, 17]\n",
      "/media/dan/34D5D1CE642D7E36/2013076_Hanfling_Bernd/Stacks/Stacks_analyses_V3/Incremental_tests/Batch_2/cru_gold_putHyb/BF04_1./MS_tests/MS_1/BF04_1.fil Coverage data.txt\n",
      "/media/dan/34D5D1CE642D7E36/2013076_Hanfling_Bernd/Stacks/Stacks_analyses_V3/Incremental_tests/Batch_2/cru_gold_putHyb/BF04_1./MS_tests/MS_2/BF04_1.fil Coverage data.txt\n",
      "/media/dan/34D5D1CE642D7E36/2013076_Hanfling_Bernd/Stacks/Stacks_analyses_V3/Incremental_tests/Batch_2/cru_gold_putHyb/BF04_1./MS_tests/MS_3/BF04_1.fil Coverage data.txt\n",
      "/media/dan/34D5D1CE642D7E36/2013076_Hanfling_Bernd/Stacks/Stacks_analyses_V3/Incremental_tests/Batch_2/cru_gold_putHyb/BF04_1./MS_tests/MS_4/BF04_1.fil Coverage data.txt\n",
      "/media/dan/34D5D1CE642D7E36/2013076_Hanfling_Bernd/Stacks/Stacks_analyses_V3/Incremental_tests/Batch_2/cru_gold_putHyb/BF04_1./MS_tests/MS_5/BF04_1.fil Coverage data.txt\n",
      "/media/dan/34D5D1CE642D7E36/2013076_Hanfling_Bernd/Stacks/Stacks_analyses_V3/Incremental_tests/Batch_2/cru_gold_putHyb/EP01_1./MS_tests/MS_1/EP01_1.fil Coverage data.txt\n",
      "/media/dan/34D5D1CE642D7E36/2013076_Hanfling_Bernd/Stacks/Stacks_analyses_V3/Incremental_tests/Batch_2/cru_gold_putHyb/EP01_1./MS_tests/MS_2/EP01_1.fil Coverage data.txt\n",
      "/media/dan/34D5D1CE642D7E36/2013076_Hanfling_Bernd/Stacks/Stacks_analyses_V3/Incremental_tests/Batch_2/cru_gold_putHyb/EP01_1./MS_tests/MS_3/EP01_1.fil Coverage data.txt\n",
      "/media/dan/34D5D1CE642D7E36/2013076_Hanfling_Bernd/Stacks/Stacks_analyses_V3/Incremental_tests/Batch_2/cru_gold_putHyb/EP01_1./MS_tests/MS_4/EP01_1.fil Coverage data.txt\n",
      "/media/dan/34D5D1CE642D7E36/2013076_Hanfling_Bernd/Stacks/Stacks_analyses_V3/Incremental_tests/Batch_2/cru_gold_putHyb/EP01_1./MS_tests/MS_5/EP01_1.fil Coverage data.txt\n",
      "/media/dan/34D5D1CE642D7E36/2013076_Hanfling_Bernd/Stacks/Stacks_analyses_V3/Incremental_tests/Batch_2/cru_gold_putHyb/GBP7_RD-P1-127_1./MS_tests/MS_1/GBP7_RD-P1-127_1.fil Coverage data.txt\n",
      "/media/dan/34D5D1CE642D7E36/2013076_Hanfling_Bernd/Stacks/Stacks_analyses_V3/Incremental_tests/Batch_2/cru_gold_putHyb/GBP7_RD-P1-127_1./MS_tests/MS_2/GBP7_RD-P1-127_1.fil Coverage data.txt\n",
      "/media/dan/34D5D1CE642D7E36/2013076_Hanfling_Bernd/Stacks/Stacks_analyses_V3/Incremental_tests/Batch_2/cru_gold_putHyb/GBP7_RD-P1-127_1./MS_tests/MS_3/GBP7_RD-P1-127_1.fil Coverage data.txt\n",
      "/media/dan/34D5D1CE642D7E36/2013076_Hanfling_Bernd/Stacks/Stacks_analyses_V3/Incremental_tests/Batch_2/cru_gold_putHyb/GBP7_RD-P1-127_1./MS_tests/MS_4/GBP7_RD-P1-127_1.fil Coverage data.txt\n",
      "/media/dan/34D5D1CE642D7E36/2013076_Hanfling_Bernd/Stacks/Stacks_analyses_V3/Incremental_tests/Batch_2/cru_gold_putHyb/GBP7_RD-P1-127_1./MS_tests/MS_5/GBP7_RD-P1-127_1.fil Coverage data.txt\n",
      "number of coverage plots = 15\n",
      "sample names =\n",
      "set(['BF04', 'EP01', 'GBP7'])\n",
      "BF04\n",
      "[23.4, 23.35, 23.41, 23.41, 23.41]\n",
      "EP01\n",
      "[22.56, 22.66, 22.68, 22.68, 22.69]\n",
      "GBP7\n",
      "[26.92, 27.39, 27.42, 27.42, 27.43]\n"
     ]
    }
   ],
   "source": [
    "IncreMental_U('MS', 1, 6, 1, '/media/dan/34D5D1CE642D7E36/2013076_Hanfling_Bernd/Stacks/Stacks_analyses_V3/Incremental_tests/Batch_2/cru_gold_putHyb/', 'fastq', 8)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make the bash file and execute with the Final chosen Ustacks parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def Final_Ustacks_command(M_value, m_value, parent_dir_path):\n",
    "       \n",
    "## Define execute function ##\n",
    "        \n",
    "    def execute(bash_file):\n",
    "        f = open(str(bash_file), 'r')\n",
    "        script = f.read()\n",
    "        subprocess.call(script, shell=True)\n",
    "        print script\n",
    "    \n",
    "## Get files ##\n",
    "    \n",
    "    sample_names = []\n",
    "    \n",
    "    for i in os.listdir(parent_dir_path):\n",
    "        if i.endswith(\".fq_1\") or i.endswith(\"1.fastq\"): \n",
    "            sample_names.append(i)\n",
    "    \n",
    "    print (\"Parameter values: M =\"+str(M_value)+\" m =\"+str(m_value)+\"\\n\")\n",
    "    \n",
    "## Write file ##\n",
    "\n",
    "    f = open(str(parent_dir_path +\"Final_Ustacks_commands.sh\"), 'w') ## .. make a bash script file in the current ipython directory...\n",
    "    f.write(\"#!/bin/bash\\n\\nmkdir \"+ parent_dir_path + \"Final_Ustacks_outputs/ \\n\") \n",
    "    \n",
    "    Sample_ID = 1\n",
    "    for sample in sample_names: ## so for each sample ...\n",
    "        final_command_list = []\n",
    "        f.write('ustacks -t fastq -M '+str(M_value)+' -m '+str(m_value)+' -p 8 -d -r -i '+str(Sample_ID)+' -f '+ str(parent_dir_path) + str(sample)+' -o '+ str(parent_dir_path) + 'Final_Ustacks_outputs/ \\n')    \n",
    "        Sample_ID += 1\n",
    "        print (sample.split(\"_\")[0]+\" ID = \"+str(Sample_ID))\n",
    "    f.close()\n",
    "    \n",
    "## Execute the scripts\n",
    "    execute(str(parent_dir_path +\"Final_Ustacks_commands.sh\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Final_Ustacks_command(8,8,'/media/dan/34D5D1CE642D7E36/2013076_Hanfling_Bernd/Stacks/Stacks_analyses_V3/Incremental_tests/Batch_2/all_cru/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
